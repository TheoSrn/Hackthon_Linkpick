services:
  # Qdrant Vector Database
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_storage:/qdrant/storage
    networks:
      - rag-network
    healthcheck:
      test: ["CMD-SHELL", "timeout 5s bash -c ':> /dev/tcp/127.0.0.1/6333' || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 10s

  # vLLM Server for LLM Inference
  vllm:
    image: vllm/vllm-openai:latest
    container_name: vllm
    ports:
      - "8000:8000"
    volumes:
      - vllm_cache:/root/.cache/huggingface
    command: >
      --model TinyLlama/TinyLlama-1.1B-Chat-v1.0
      --dtype float16
      --max-model-len 2048
      --gpu-memory-utilization 0.9
    networks:
      - rag-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

  # Document Indexer (runs once to index PDFs)
  indexer:
    build:
      context: ./indexer
      dockerfile: Dockerfile
    container_name: indexer
    volumes:
      - ./dataset:/data:ro
    environment:
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
    depends_on:
      qdrant:
        condition: service_healthy
    networks:
      - rag-network
    restart: "no"

  # Backend API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: backend
    ports:
      - "8001:8001"
    environment:
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - VLLM_HOST=vllm
      - VLLM_PORT=8000
    depends_on:
      qdrant:
        condition: service_healthy
      vllm:
        condition: service_healthy
      indexer:
        condition: service_completed_successfully
    networks:
      - rag-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 30s

  # Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: frontend
    ports:
      - "80:80"
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - rag-network

volumes:
  qdrant_storage:
  vllm_cache:

networks:
  rag-network:
    driver: bridge
